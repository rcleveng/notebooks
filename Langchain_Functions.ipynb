{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2AcD5QXtX6Bhs810cVjJB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcleveng/notebooks/blob/main/Langchain_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple langchain example using Google's Generate AI API.\n",
        "\n",
        "You'll need an API key from Generative AI Studio.\n"
      ],
      "metadata": {
        "id": "2Y7r3isO2tpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fist we install dependencies to use langserv."
      ],
      "metadata": {
        "id": "a6qxLwH_ETzz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AVlTEDo1lD2"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-cli \"langserve[all]\" google.generativeai | grep -v 'already satisfied' && echo \"Installed dependencies\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import for using secrets in colab\n",
        "from google.colab import userdata\n",
        "\n",
        "# basic langchain imports\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chat_models import google_palm\n",
        "from langchain.chat_models import ChatGooglePalm\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "\n",
        "\n",
        "# Import things for functions\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "# agents\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "\n",
        "# Get the key from https://makersuite.google.com\n",
        "# Add your PALM_KEY as a secret to colab.\n",
        "\n",
        "google_api_key = userdata.get('PALM_KEY')"
      ],
      "metadata": {
        "id": "qY1bz3EyTqIa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIMPLE_TEMPLATE=\"\"\"\n",
        "You are a helpful bot.\n",
        "Answer to the question to the best of your ability.\n",
        "If you do not know an answer state so.\n",
        "\n",
        "Question: {question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ozoMt926Tt95"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this to turn on debugging and verbose output on all chains"
      ],
      "metadata": {
        "id": "bCdJxsP_b852"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_verbose\n",
        "from langchain.globals import set_debug\n",
        "\n",
        "set_verbose(True)\n",
        "set_debug(True)"
      ],
      "metadata": {
        "id": "aj_pwe-Sb8hZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numexpr as ne\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(SIMPLE_TEMPLATE)\n",
        "model = ChatGooglePalm(google_api_key=google_api_key)\n",
        "\n",
        "class SearchInput(BaseModel):\n",
        "    query: str = Field(description=\"should be used to search the internet for current events\", default=\"\")\n",
        "\n",
        "@tool(\"search-tool\", args_schema=SearchInput, return_direct=True)\n",
        "def search(query: str) -> str:\n",
        "    \"\"\"Search the internet for current events.\"\"\"\n",
        "    print(\"executing search-tool\")\n",
        "    return \"LangChain SEARCH AGENT\"\n",
        "\n",
        "class CalculatorTool(BaseModel):\n",
        "    query: str = Field(description=\"should be used to calculate math\", default=\"\")\n",
        "\n",
        "@tool(\"calculator-tool\", args_schema=SearchInput, return_direct=True)\n",
        "def calculate(query: str) -> str:\n",
        "    \"\"\"should be used to calculate math\"\"\"\n",
        "    print(\"executing calculator-tool\")\n",
        "    return str(ne.evaluate(query).item())\n",
        "    return \"LangChain CALCULATOR AGENT\"\n",
        "\n",
        "tools = [calculate, search]\n",
        "\n",
        "# initialize conversational memory\n",
        "conversational_memory = ConversationBufferWindowMemory(\n",
        "        memory_key='chat_history',\n",
        "        k=5,\n",
        "        return_messages=True)\n",
        "\n",
        "# initialize agent with tools\n",
        "agent = initialize_agent(\n",
        "    agent='chat-conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=model,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method='generate',\n",
        "    memory=conversational_memory\n",
        ")\n",
        "\n",
        "out1 = agent.invoke(\"why is the sky blue?\")\n",
        "out2 = agent.invoke(\"What is 10 * 10?\")\n",
        "out3 = agent.invoke(\"How much is it if you add 20 to that?\")\n",
        "\n",
        "print(\"*** OUTPUT: \", out1['output'])\n",
        "print(\"*** OUTPUT: \", out2['output'])\n",
        "print(\"*** OUTPUT: \", out3['output'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vrkmNlO92EUD",
        "outputId": "fcb86dcb-6df0-4834-8825-7753cd3273b7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"why is the sky blue?\",\n",
            "  \"chat_history\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"why is the sky blue?\",\n",
            "  \"chat_history\": [],\n",
            "  \"agent_scratchpad\": [],\n",
            "  \"stop\": [\n",
            "    \"\\nObservation:\",\n",
            "    \"\\n\\tObservation:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatGooglePalm] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> calculator-tool: calculator-tool(query: str) -> str - should be used to calculate math\\n> search-tool: search-tool(query: str) -> str - Search the internet for current events.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of calculator-tool, search-tool\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nwhy is the sky blue?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatGooglePalm] [5.27s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\\n\\nHere is a markdown code snippet of a json blob with a single action:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\\\"\\n}\\n```\",\n",
            "        \"generation_info\": null,\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"ChatMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"role\": \"1\",\n",
            "            \"content\": \"The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\\n\\nHere is a markdown code snippet of a json blob with a single action:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\\\"\\n}\\n```\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [5.28s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \"The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\\n\\nHere is a markdown code snippet of a json blob with a single action:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": \\\"The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\\\"\\n}\\n```\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [5.28s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatGooglePalm] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\nHuman: why is the sky blue?\\nAI: The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> calculator-tool: calculator-tool(query: str) -> str - should be used to calculate math\\n> search-tool: search-tool(query: str) -> str - Search the internet for current events.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of calculator-tool, search-tool\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nWhat is 10 * 10?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatGooglePalm] [2.11s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Sure! I can help you with that.\\n\\n```json\\n{\\n    \\\"action\\\": \\\"calculator-tool\\\",\\n    \\\"action_input\\\": \\\"10 * 10\\\"\\n}\\n```\",\n",
            "        \"generation_info\": null,\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Sure! I can help you with that.\\n\\n```json\\n{\\n    \\\"action\\\": \\\"calculator-tool\\\",\\n    \\\"action_input\\\": \\\"10 * 10\\\"\\n}\\n```\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [2.11s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \"Sure! I can help you with that.\\n\\n```json\\n{\\n    \\\"action\\\": \\\"calculator-tool\\\",\\n    \\\"action_input\\\": \\\"10 * 10\\\"\\n}\\n```\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:calculator-tool] Entering Tool run with input:\n",
            "\u001b[0m\"10 * 10\"\n",
            "executing calculator-tool\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:calculator-tool] [0ms] Exiting Tool run with output:\n",
            "\u001b[0m\"100\"\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [2.12s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"100\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatGooglePalm] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\nHuman: why is the sky blue?\\nAI: The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\\nHuman: What is 10 * 10?\\nAI: 100\\nHuman: TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> calculator-tool: calculator-tool(query: str) -> str - should be used to calculate math\\n> search-tool: search-tool(query: str) -> str - Search the internet for current events.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": string, \\\\\\\\ The action to take. Must be one of calculator-tool, search-tool\\n    \\\"action_input\\\": string \\\\\\\\ The input to the action\\n}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{\\n    \\\"action\\\": \\\"Final Answer\\\",\\n    \\\"action_input\\\": string \\\\\\\\ You should put what you want to return to use here\\n}\\n```\\n\\nUSER'S INPUT\\n--------------------\\nHere is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nHow much is it if you add 20 to that?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatGooglePalm] [3.10s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Sure, I can help you with that.\\n\\n```json\\n{\\n    \\\"action\\\": \\\"calculator-tool\\\",\\n    \\\"action_input\\\": \\\"100 + 20\\\"\\n}\\n```\",\n",
            "        \"generation_info\": null,\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Sure, I can help you with that.\\n\\n```json\\n{\\n    \\\"action\\\": \\\"calculator-tool\\\",\\n    \\\"action_input\\\": \\\"100 + 20\\\"\\n}\\n```\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [3.10s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \"Sure, I can help you with that.\\n\\n```json\\n{\\n    \\\"action\\\": \\\"calculator-tool\\\",\\n    \\\"action_input\\\": \\\"100 + 20\\\"\\n}\\n```\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:calculator-tool] Entering Tool run with input:\n",
            "\u001b[0m\"100 + 20\"\n",
            "executing calculator-tool\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:calculator-tool] [1ms] Exiting Tool run with output:\n",
            "\u001b[0m\"120\"\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [3.11s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"120\"\n",
            "}\n",
            "*** OUTPUT:  The sky is blue because of a phenomenon called Raleigh scattering. This scattering refers to the scattering of electromagnetic radiation (of which light is a form) by particles of a much smaller wavelength. Sunlight is scattered by the tiny molecules of air in Earth's atmosphere. Blue light is scattered more than the other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time.\n",
            "*** OUTPUT:  100\n",
            "*** OUTPUT:  120\n"
          ]
        }
      ]
    }
  ]
}